 If I say, the cat purrs, or this cat hunts mice, it's perfectly reasonable to also say, the kitty purrs, or this kitty hunts mice. The context gives you a strong idea that those words are similar. You have to be cat-like to purr and hunt mice. So let's learn to predict a word's context. The hope is that a model that's good at predicting a word's context will have to treat cat and kitty similarly. And will tend to bring them closer together. The beauty of this approach is that you don't have to worry about what the words actually mean. You infer their meaning directly by the company they keep. There are many ways to use this idea that similar words occur in similar contexts. In our case, we're going to use it to map words to small vectors called embeddings, which are going to be close to each other when words have similar meanings and far apart when they don't. Embedding solves some of the sparsity problem. Once you have embedded your word into this small vector, now you have a word representation where all the cat-like things, like cats, kitties, kittens, pets, lions, are all represented by vectors that are very similar. Your model no longer has to learn new things for every way there is to talk about a cat. It can generalize from this particular pattern of cat-like things.